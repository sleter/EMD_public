{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic modeling\n",
    "\n",
    "Zadanie proszę wykonać w parach, ale... na dwóch komputerach. Na obu komputerach proszę najpierw wykonać instrukcje z sekcji **Przygotowanie**. Następnie na jednym komputerze proszę od razu odkomentować i uruchomić kod w sekcji **Wikipedia** i **Wizualizacja**. Na drugim komputerze proszę rozwiązać zadania z sekcji **Tweety** i **Wizualizacja**.\n",
    "\n",
    "Po wykonaniu tego zadania powinieneś:\n",
    "+ potrafić wykonać podstawowy topic modeling,\n",
    "+ umieć stworzyć słownik mapujący identyfikatory na słowa,\n",
    "+ potrafić stworzyć macierz wektorów TF-IDF,\n",
    "+ wiedzieć jak wykorzystać LDA do określenia proporcji tematów w nowym dokumencie tekstowym,\n",
    "+ potrafić zwizualizować wyniki algorytmu LDA.\n",
    "\n",
    "Do wykonania zadania wykorzystamy bibliotekę [gensim](https://radimrehurek.com/gensim/), która oferuje szereg metod do analizy tekstu. Warto w wolnej chwili zobaczyć co oprócz algorytmu LDA zostało zaimplementowane w ramach tego modułu!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przygotowanie\n",
    "\n",
    "Aby zadziałała wizualizacja, musimy najpierw zauktualizować bibliotekę `scipy` i doinstalować bibliotekę `pyldavis`. Będzie to okazja, żeby zobaczyć jak zarządza się bibliotekami w anacondzie. Jeśli kogoś interesuje co oznaczają kolejne komendy, proszę zajrzeć do [dokumentacji Anacondy](http://conda.pydata.org/docs/using/pkgs.html).\n",
    "\n",
    "1. Zatrzymaj kernel (serwer jupyter notebooka)\n",
    "2. Otwórz terminal\n",
    "3. Wpisz `conda update scipy` (i Enter gdy spytają `Proceed`)\n",
    "4. Popatrz na paski postępu\n",
    "5. Wpisz `activate root`\n",
    "6. Wpisz `pip install pyldavis`\n",
    "7. Wpisz `deactivate`\n",
    "\n",
    "Koniec. Możesz ponownie odpalić notatnik i przejść do kolejnych kroków."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikipedia\n",
    "\n",
    "Ten fragemnt kodu stanowi przykład uruchomienia topic modelingu na większym zbiorze danych. Ponieważ wyliczenie modelu będzie trwać od kilku do kilkunastu minut, niech każda para uruchomi ten przykład tylko na jednym komputerze.\n",
    "\n",
    "Aby uruchomić przykład, w folderze z notatnikiem muszą znajdować się pliki `wiki_wordids.txt.bz2` i `wiki_tfidf.mm` ściągnięte wraz z notatnikiem. Przykład zbudowany jest w oparciu o podzbiór stron wikipedii dostępny pod adresem: https://dumps.wikimedia.org/enwiki/latest/. Strony zostały przekonwertowane na reprezentację wektorową za pomocą skryptu:\n",
    "`python -m gensim.scripts.make_wiki`.\n",
    "\n",
    "**Przeczytaj komentarze zanim uruchomisz kod.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import logging\n",
    "# import gensim\n",
    "\n",
    "# # Włączamy logowanie, żeby śledzić postępy algorytmu (to akurat nie będzie działać w Jupyter Notebooku,\n",
    "# # ale warto o tym wspomnieć)\n",
    "# logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "# # Odczytujemy z pliku mapowanie/słownik id->słowo\n",
    "# id2word = gensim.corpora.Dictionary.load_from_text('wiki_wordids.txt.bz2')\n",
    "\n",
    "# # Odczytujemy z pliku reprezentację wektorową korpusu (macierz wetkorów TF-IDF)\n",
    "# mm = gensim.corpora.MmCorpus('wiki_tfidf.mm')\n",
    "# print(mm)\n",
    "\n",
    "# # Tworzymy model LDA z 20 grupami wykonując 20 iteracji na całym zbiorze\n",
    "# lda = gensim.models.LdaMulticore(corpus=mm, id2word=id2word, num_topics=20, passes=20, workers=4)\n",
    "# # Alternatywnie w razie problemów z wielowątkowością:\n",
    "# # lda = gensim.models.ldamodel.LdaModel(corpus=mm, id2word=id2word, num_topics=20, update_every=0, passes=20)\n",
    "# lda.print_topics(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweety\n",
    "\n",
    "W parach stwórzcie model LDA w oparciu o załączone Tweety. W tym celu należy przekonwertować pliki tekstowe na reprezentację wektorową zapisując wcześniej mapowanie id->słowo w postaci słownika. Opis jak stworzyć wymienione struktury danych można znaleźć na stronie: https://radimrehurek.com/gensim/tut1.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zad. 1: Wczytaj tweety z pliku tweets.tsv do zmiennej `tweets`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import logging\n",
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "stopwords = [\"a\", \"about\", \"after\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\",\n",
    "            \"before\", \"being\", \"between\", \"both\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"during\", \"each\",\n",
    "            \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\",\n",
    "            \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\",\n",
    "            \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"of\",\n",
    "            \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"own\", \"shan't\", \"she\", \"she'd\",\n",
    "            \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\",\n",
    "            \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\",\n",
    "            \"they've\", \"this\", \"those\", \"through\", \"to\", \"until\", \"up\", \"very\", \"was\", \"wasn't\", \"we\", \"we'd\",\n",
    "            \"we'll\", \"we're\", \"we've\", \"were\", \"weren't\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\",\n",
    "            \"which\", \"while\", \"who\", \"who's\", \"whom\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\",\n",
    "            \"your\", \"yours\", \"yourself\", \"yourselves\", \"above\", \"again\", \"against\", \"aren't\", \"below\", \"but\", \"can't\",\n",
    "            \"cannot\", \"couldn't\", \"didn't\", \"doesn't\", \"don't\", \"down\", \"few\", \"hadn't\", \"hasn't\", \"haven't\", \"if\",\n",
    "            \"isn't\", \"mustn't\", \"no\", \"nor\", \"not\", \"off\", \"out\", \"over\", \"shouldn't\", \"same\", \"too\", \"under\", \"why\",\n",
    "            \"why's\", \"won't\", \"wouldn't\"]\n",
    "\n",
    "tweets = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zad. 2: Dokonaj tokenizacji słów, usuń te z stoplisty (`stopwords`) oraz występujące tylko raz. Wynik przypisz do zmiennej `texts`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts = None "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zad. 3: Stwórz słownik id->słowo i przypisz do zmiennej `id2word`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id2word = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zad. 4: Stwórz reprezentację wektorową korpusu (macierz wektorów TF-IDF), wynik przypisz do zmiennej `mm`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mm=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zad. 5: Odpal poniższy kod i odkryj 10 tematów za pomocą algorytmu LDA. Jeśli masz czas, zwiększ wartości parametrów num_topics i passes przy tworzeniu modelu LDA, i sprawdź jak to wpłynie na rezultat.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Włączamy logowanie, żeby śledzić postępy algorytmu (to akurat nie będzie działać w Jupyter Notebooku,\n",
    "# # ale warto o tym wspomnieć)\n",
    "# logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "#\n",
    "# lda = gensim.models.ldamodel.LdaModel(corpus=mm, id2word=id2word, num_topics=10, update_every=0, passes=20)\n",
    "# # alternatywnie lda = gensim.models.LdaMulticore(corpus=mm, id2word=id2word, num_topics=10, passes=20)\n",
    "# lda.print_topics(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zad. 6*: Na podstawie zbudowanego modelu określ proporcje tematów w następującym tweecie:\n",
    "`Zlatan is looking mighty attractive at the moment,if LVG doesn't get a striker by Tuesday, I really don't fancy us scoring goals this season`. Jeśli zostało niewiele czasu, przejdź od razu do wizualizacji.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# new_tweet = \"Zlatan is looking mighty attractive at the moment,if LVG doesn't get a striker by Tuesday, I really don't fancy us scoring goals this season\"\n",
    "# new_tweet_text = ???\n",
    "# new_tweet_mm = id2word.doc2bow(new_tweet_text)\n",
    "# new_tweet_lda = ???\n",
    "# print(new_tweet_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wizualizacja\n",
    "\n",
    "Spróbujemy teraz zwizualizować uzyskane tematy. Podążaj za komentarzami a powinno się udać.\n",
    "\n",
    "P.S. Możesz uruchomić tę wizualizację również dla tematów odkrytych z Wikipedii...\n",
    "\n",
    "**Zad. 7: Zwizualizuj uzyskane tematy.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Poniższy kod korzysta modułu pyLDAvis z githuba:\n",
    "# # https://github.com/bmabey/pyLDAvis\n",
    "\n",
    "# import pyLDAvis\n",
    "# import pyLDAvis.gensim\n",
    "# pyLDAvis.enable_notebook()\n",
    "\n",
    "# pyLDAvis.gensim.prepare(lda, mm, id2word)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
