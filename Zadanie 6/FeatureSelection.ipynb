{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selekcja i ekstrakcja cech za pomocą scikit-learn\n",
    "\n",
    "Ten notatnik pomoże Ci zapoznać się z metodami przetwarzania wstępnego danych w Pythonie. Po uzupełnieniu tego notatnika powinieneś:\n",
    "\n",
    "+ zapoznać się klasą Pipeline,\n",
    "+ wiedzieć jak znormalizować dane,\n",
    "+ umieć uruchomić algorytm selekcji cech,\n",
    "+ wiedzieć jak wykonać analizę PCA\n",
    "\n",
    "Wszystkie algorytmy będziemy uruchamiać na jednym zbiorze danych: [Boston Housing Dataset](https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "Podczas przetwarzania wstępnego danych należy uważać, żeby nie korzystać z danych testowych. Wszakże jeśli nasz model zostanie uruchomiany na danych produkcyjnych będą to zupełnie nowe danych i nie będziemy zbyt dużo o nich wiedzieć w trakcie dokonywania predykcji.\n",
    "\n",
    "Aby ułatwić użytkownikom biblioteki `scikit-learn` przetwarzanie wstępne z możliwością rozróżnienia danych treningowych od testowych, wprowadzono klasę `Pipeline`. Klasa `Pipeline` definiuje sekwencje kroków (transformacji), które należy wykonać na danych. Kolejnymi krokami pipeline'a mogą być:\n",
    "\n",
    "- inżynieria nowych cech\n",
    "- normalizacja danych\n",
    "- usuwanie outlierów\n",
    "- selekcja cech\n",
    "- ekstrakcja cech\n",
    "- uczenie klasyfikatora\n",
    "\n",
    "Typowe pipeline'y są z reguły znacznie krótsze ;) Przydatna dokumentacja jak zwykle na stronie scikit-learn: [Pipeline](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html).\n",
    "\n",
    "**Zad. 1: Załaduj wskazany zbiór danych i stwórz swój pierwszy pipeline. Pipeline powinien mieć dwa kroki: normalizację danych i uczenie regresora.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 3.6494\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "SEED = 23\n",
    "\n",
    "# 0. Zbiór danych\n",
    "boston = load_boston()\n",
    "X = boston[\"data\"]\n",
    "y = boston[\"target\"]\n",
    "names = boston[\"feature_names\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=SEED)\n",
    "\n",
    "# 1. stwórz obiekt do normalizacji danych\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 2. stwórz klasyfikator\n",
    "clf = RandomForestRegressor()\n",
    "\n",
    "# 3. stwórz Pipeline z dwoma krokami, kroki nazwij \"scaler\" i \"clf\" i niech zawierają obiekty scaler i clf\n",
    "pipe = Pipeline([('scaler', scaler), ('clf', clf)])\n",
    "\n",
    "# 4. Odpal pipeline\n",
    "clf_fit = pipe.fit(X_train, y_train)\n",
    "y_true, y_pred = y_test, clf_fit.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "print(\"RMSE: %.4f\" % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Pipeline` działa trochę jak klasyfikator połączony ze wstępnym przetwarzaniem. Można zatem podać stworzony przez siebie obiekt typu `Pipeline` jako parametr `GirdSearchCV`. Ale zanim do tego przejdziemy skupmy się na metodach selekcji cech."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selekcja cech\n",
    "\n",
    "W poniższych sekcjach szybko spojrzymy na implementacje różnych metod selekcji cech w bibliotece `scikit-learn`. Warto zaznaczyć, że selekcja cech to bardzo szeroka działka naukowa i algorytmów jest multum. Stosunkowo niedawno pojawiła się biblioteka [`scikit-feature`](http://featureselection.asu.edu/), która rozszerza zbiór algorytmów dostępnych w `scikit-learn`. [`scikit-feature`](http://featureselection.asu.edu/) nie jest biblioteką, która jest oficjalnie wspierana przez ludzi tworzących `scikit-learn`, ale może to być dobre miejsce do poszukiwań implementacji mniej popularnych algorytmów."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metody filter\n",
    "\n",
    "Zacznijmy od zbadania wariancji. Do tego przyda Ci się klasa [`Variancethreshold`](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.VarianceThreshold.html). Jeśli wariancja jest zero (kolumna ma tylko jedną wartość) na pewno warto sprawdzić czy to nie jakiś błąd. Jeśli dana kolumna to po prostu stała, można ją z czystym sumieniem usunać. Mając rozeznanie w danych, można również ustawić minimalny próg zmienności.\n",
    "\n",
    "**Zad. 2: Sprawdź czy w zbiorze danych są atrybuty o zmienności mniejszej niż 0.05.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of attributes: 13\n",
      "Num of attributes: 13\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# 1. Sprawdź ile atrybutów ma zbiór danych\n",
    "print(f'Num of attributes: {X_train.shape[1]}')\n",
    "# 2. Użyj metody fit_transform na obiekcie klasy VarianceThreshold\n",
    "X_v = VarianceThreshold().fit_transform(X_train)\n",
    "# 3. Sprawdź ile atrybutów ma przetransformowany zbiór danych\n",
    "print(f'Num of attributes: {X_v.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inną prostą metodą jest badanie korelacji między zmiennymi a wartością przewidywaną. W `scikit-learn` służą do tego metody `chi2`, `f_classif` i `f_regression`. Ponieważ przewidujemy wartość ciągłą, sprawdźmy działanie tej ostatniej. Uwaga! Metody te oceniają każdą cechę osobno, dlatego cechy skorelowane będą podobnie ocenione.\n",
    "\n",
    "**Zad. 3: Oceń atrybuty na podstawie ich korelacji z atrybutem decyzyjnym.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRIM: 78.50 (p=0.000)\n",
      "ZN: 63.28 (p=0.000)\n",
      "INDUS: 106.05 (p=0.000)\n",
      "CHAS: 12.59 (p=0.000)\n",
      "NOX: 86.93 (p=0.000)\n",
      "RM: 366.32 (p=0.000)\n",
      "AGE: 72.51 (p=0.000)\n",
      "DIS: 29.16 (p=0.000)\n",
      "RAD: 67.46 (p=0.000)\n",
      "TAX: 106.88 (p=0.000)\n",
      "PTRATIO: 132.46 (p=0.000)\n",
      "B: 55.38 (p=0.000)\n",
      "LSTAT: 473.74 (p=0.000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "# 1. Odpalf_regression, aby uzyskać ocenę korelacji\n",
    "f_scores, p_values = f_regression(X_train, y_train)\n",
    "\n",
    "# 2. Wypisz wynik dla każdego atrybutu\n",
    "for i in range(len(names)):\n",
    "    print('{0}: {1:.2f} (p={2:.3f})'.format(names[i], f_scores[i], p_values[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Znając korelację bądź inną wartość oceniającą atrybuty, możemy wybrać podzbioru najlepszych atrybutów. Do tego służą klasy `SelectKBest` i `SelectPercentile`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 3.8157\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "\n",
    "# 1. Stwórz obiekt SelectKBest z odpowiednimi parametrami\n",
    "skb = SelectKBest(f_regression, k=10)\n",
    "# 2. Stwórz pipeline z krokami scaler, selector i clf\n",
    "pipe = Pipeline([('scaler', scaler), ('selector', skb), ('clf', clf)])\n",
    "# 3. Odpal pipeline i oceń predykcje tak jak to zrobiłeś w zadaniu 1.\n",
    "clf_fit = pipe.fit(X_train, y_train)\n",
    "y_true, y_pred = y_test, clf_fit.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "print(\"RMSE: %.4f\" % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zad. 5: Powtórz poprzednie zadanie wykorzystując tym razem miarę `mutual_info_regression`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 3.6518\n"
     ]
    }
   ],
   "source": [
    "# 1. Stwórz obiekt SelectKBest z odpowiednimi parametrami\n",
    "skb = SelectKBest(mutual_info_regression, k=10)\n",
    "# 2. Stwórz pipeline z krokami scaler, selector i clf\n",
    "pipe = Pipeline([('scaler', scaler), ('selector', skb), ('clf', clf)])\n",
    "# 3. Odpal pipeline i oceń predykcje tak jak to zrobiłeś w zadaniu 1.\n",
    "clf_fit = pipe.fit(X_train, y_train)\n",
    "y_true, y_pred = y_test, clf_fit.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "print(\"RMSE: %.4f\" % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metody wrapper\n",
    "\n",
    "Klasyczne metody typu wrapper nie są dostępne jako funkcje w `scikit-learn`. Można samemu zaimplementować brute-force, forward selction bądź backward selection lub... posiłkować się biblioteką [`mlxtend`](http://rasbt.github.io/mlxtend/) i zawartymi tam klasami `ExhaustiveFeatureSelector` (brute-force) i `SequentialFeatureSelector` (backward/foward selection). Biblioteka `mlxtend` zawiera wiele innych bardzo ciekawych rozszerzeń do `scikit-learn` (np. Stacking czy EnsembleVote) więc warto pamiętać o tej bibliotece.\n",
    "\n",
    "Zamiast rozwodzić się nad klasycznymi metodami typu wrapper, które są bardzo kosztowne obliczeniowo, wypróbujmy algorytm RFE. Dla przypomnienia, algorytm RFE ocenia atrybuty a następnie usuwa najsłabszy z nich. Czynność ta jest powtarzana aż uzyskamy oczekiwaną liczbę atrybutów.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zad. 6: Skorzystaj z klasy [`RFECV`](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html) aby znaleźć najlepszy podzbiór atrybutów. Użyj 10-krotnej oceny krzyżowej.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRIM: 1\n",
      "ZN: 4\n",
      "INDUS: 2\n",
      "CHAS: 5\n",
      "NOX: 1\n",
      "RM: 1\n",
      "AGE: 1\n",
      "DIS: 1\n",
      "RAD: 3\n",
      "TAX: 1\n",
      "PTRATIO: 1\n",
      "B: 1\n",
      "LSTAT: 1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "# 1. Odpal RFECV na danych treningowych\n",
    "selector = RFECV(clf, step=1, cv=10).fit(X_train, y_train)\n",
    "# 2. Wypisz ranking atrybutów\n",
    "for i in range(len(names)):\n",
    "    print('{0}: {1}'.format(names[i], selector.ranking_[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bardzo fajną hybrydą jest również algorytm Stability Selection. Jest to algorytm dość kosztowny ale łączy elementy interpretacji atrybutów oraz poprawiania trafności predykcji. Zainteresowani mogą zajrzeć do klas [`RandomizedLogisticRegression`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RandomizedLogisticRegression.html) (klasyfikacja) i [`RandomizedLasso`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RandomizedLasso.html#sklearn.linear_model.RandomizedLasso) (regresja) w dokumentacji `scikit-learn`. Obie klasy są obecnie DEPRACATED, ale liczę że po prostu przeniosą je do modułu `feature_selection`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metody embedded\n",
    "\n",
    "Modele liniowe są od lat stosowane do określania ważności atrybutów. Modele liniowe bez regularyzacji potrafią wskazać ważność atrybutów jeśli dane nie są zbyt mocono zaszumione i atrybuty nie są ze sobą skorelowane.\n",
    "\n",
    "Modele liniowe z regularyzacją radzą sobie lepiej z szumem i korelacją. Regularyzacja L1 (LASSO) usuwa atrybuty i może być stosowana do selekcji cech w celu poprawy trafności predykcji. Regularyzacja L2 (Ridge regression) jest bardzie stabilna, nie usuwa atrybutów i może być stosowania do oceny atrybutów w celach interpretacyjnych.\n",
    "\n",
    "**Zad. 7: Naucz modele liniowe i sprawdź wagi przypisane kolejnym atrybutom by ocenić ich ważność. Nie zapomnij  oznormalizowaniu danych.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso model:  -3.797 * LSTAT + 3.003 * RM + -1.541 * PTRATIO + -1.024 * DIS + 0.883 * B + 0.746 * CHAS + -0.557 * NOX + 0.2 * ZN + -0.061 * CRIM + -0.0 * INDUS + -0.0 * AGE + 0.0 * RAD + -0.0 * TAX\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ridge model:  -3.794 * LSTAT + -3.047 * DIS + 2.772 * RM + 2.389 * RAD + -2.159 * NOX + -1.88 * PTRATIO + -1.555 * TAX + 1.149 * B + 1.109 * ZN + 0.864 * CHAS + -0.797 * CRIM + 0.167 * INDUS + 0.055 * AGE\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge\n",
    "\n",
    "def pretty_print_linear(coefs, names = None, sort = False):\n",
    "    if names is None:\n",
    "        names = [\"X%s\" % x for x in range(len(coefs))]\n",
    "    lst = zip(coefs, names)\n",
    "    if sort:\n",
    "        lst = sorted(lst,  key = lambda x:-np.abs(x[0]))\n",
    "    return \" + \".join(\"%s * %s\" % (round(coef, 3), name) for coef, name in lst)\n",
    "\n",
    "# 1. Odpal Lasso z alpha=0.3 w pipeline'ie z normalizacją\n",
    "lasso = Lasso(alpha=0.3)\n",
    "lasso_pipe = Pipeline([('scaler', scaler), ('lasso', lasso)])\n",
    "lasso_pipe.fit(X_train, y_train)\n",
    "\n",
    "# 2. Odpal Ridge z alpha=0.3 w pipeline'ie z normalizacją\n",
    "ridge = Ridge(alpha=0.3)\n",
    "ridge_pipe = Pipeline([('scaler', scaler), ('ridge', ridge)])\n",
    "ridge_pipe.fit(X_train, y_train)\n",
    "\n",
    "# 3. Wypisz uzyskane modele\n",
    "print(\"Lasso model: \", pretty_print_linear(lasso_pipe.steps[1][1].coef_, names, sort = True))\n",
    "print('-'*100)\n",
    "print(\"Ridge model: \", pretty_print_linear(ridge_pipe.steps[1][1].coef_, names, sort = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ekstrakcja cech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na koniec zobaczymy jak w Pythonie policzyć PCA i na tej podstawie zmniejszyć liczbę atrybutów. Uwaga! Trzeba znormalizować dane przed analizą PCA, aby nie przecenić atrybutów o większym zakresie wartości i wten sposób nie wykonać gorszej transformacji.\n",
    "\n",
    "**Zad. 8: Wykonaj analizę PCA zgodnie z poniższymi krokami.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 4.0527\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# 1. Znormalizuj dane, odpal PCA i zobacz ile atrybutów potrzeba do wyjaśnienia zmienności w danych\n",
    "pca = Pipeline([('scaler', scaler), ('extractor', PCA())])\n",
    "pca.fit(X_train)\n",
    "\n",
    "plt.figure(1, figsize=(8, 6))\n",
    "plt.plot(pca.steps[1][1].explained_variance_, linewidth=2)\n",
    "plt.xlabel('n_components')\n",
    "plt.ylabel('explained_variance')\n",
    "\n",
    "# 2. Stwórz nowy obiekt PCA i ogranicz liczbę cech do określonej na podstawie wykresu liczby\n",
    "pca = PCA(n_components=10)\n",
    "# 3. Stwórz pipeline z krokami scaler, extractor i clf\n",
    "pipe = Pipeline([('scaler', scaler), ('extractor', pca), ('clf', clf)])\n",
    "# 4. Odpal pipeline i oceń predykcje tak jak to zrobiłeś w zadaniu 1.\n",
    "clf_fit = pipe.fit(X_train, y_train)\n",
    "y_true, y_pred = y_test, clf_fit.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "print(\"RMSE: %.4f\" % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie bonusowe\n",
    "\n",
    "**Zad. 9*: Zaimplementuj grid search, który wypróbuje wiele metod selekcji cech (potencjalnie z różnymi parametrami) i wybierze najlepsze wstępne przetwarzanie danych.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__n_estimators': 150, 'clf__random_state': 1337, 'extractor': PCA(n_components=13), 'extractor__n_components': 13, 'feature_selection': 'passthrough', 'scaler': 'passthrough'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "RMSE: 3.9995010721209634\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler', None),\n",
    "    ('extractor', None),\n",
    "    ('feature_selection', None),\n",
    "    ('clf', RandomForestRegressor())])\n",
    "\n",
    "parameters = dict(\n",
    "    scaler = ['passthrough', StandardScaler(), RobustScaler()],\n",
    "    extractor = [PCA()],\n",
    "    extractor__n_components = [5, 10 , 13],\n",
    "    feature_selection = ['passthrough', Lasso(), Ridge()],\n",
    "    clf__n_estimators = [100, 150],\n",
    "    clf__random_state = [1337]\n",
    ")\n",
    "\n",
    "clf = GridSearchCV(pipe, parameters)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(clf.best_params_)\n",
    "print('-'*100)\n",
    "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, clf.predict(X_test)))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
